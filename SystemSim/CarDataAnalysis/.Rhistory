install.packages("pacman")
install.packages("pacman")
library(pacman)
# Install class for knn classification
pacman::p_load("class")
# Load Data ############################
# Read csv
dataIris <- read.csv("car_data.csv", header = TRUE)
View(dataIris)
# Load Data ############################
# Read csv
dataIris <- read.csv("car_data.csv", header = TRUE)
colnames(dataIris)
head(dataIris)       # Show the first 6 cases
normal <- function(x) {
norm <- ((x - min(x))/(max(x)- min(x)))
return (norm)
}
# Apply function to data frame without ID and default
normalDataIris <- as.data.frame(lapply(dataIris[,1:6], normal))
# Apply function to data frame without ID and default
normalDataIris <- as.data.frame(lapply(dataIris[,1:7], normal))
# Apply function to data frame without ID and default
normalDataIris <- as.data.frame(lapply(dataIris[,1:5], normal))
# Apply function to data frame without ID and default
normalDataIris <- as.data.frame(lapply(dataIris[,1:4], normal))
# Apply function to data frame without ID and default
normalDataIris <- as.data.frame(lapply(dataIris[,1:6], normal))
head(normalDataIris)
# Put outcome variable back on and rename
normalDataIris <- cbind(normalDataIris, dataIris[,7])
names(normalDataIris)[7] <- "class"
# Check Data
colnames(normalDataIris)
head(normalDataIris)
# Split into training set (80%) and testing set (20%)
set.seed(800) #seed can be any number
normalDataIris.split <- sample(2, nrow(normalDataIris),replace = TRUE, prob = c(0.8, 0.2))
# Create training and testing dataset without outcome labels.
# Use just the first 23 variavles
normalDataIris.train.labels <- normalDataIris[normalDataIris.split == 1, 5]
normalDataIris.test.labels <- normalDataIris[normalDataIris.split == 2, 5]
# Create outcome labels
normalDataIris.train <- normalDataIris[normalDataIris.split == 1, 1:4]
normalDataIris.test <- normalDataIris[normalDataIris.split == 2, 1:4]
# Build classifier for test data
# k = number of neighbors to compare; odd n avoids ties.
# Try for several k and check accuracy
normalDataIris.pred <- knn(train = normalDataIris.train,
test = normalDataIris.test,
cl = normalDataIris.train.labels,       # true class
k = 3)                         # n neighbors
# Compare predicted outcome to observed outcome
table(normalDataIris.pred, normalDataIris.test.labels)
# Clean up #####################
rm(list = ls())
install.packages("pacman")
install.packages("pacman")
library(pacman)
# Install class for knn classification
pacman::p_load("class")
# Load Data ############################
# Read csv
dataIris <- read.csv("car_data.csv", header = TRUE)
colnames(dataIris)
head(dataIris)       # Show the first 6 cases
normal <- function(x) {
norm <- ((x - min(x))/(max(x)- min(x)))
return (norm)
}
# Apply function to data frame without ID and default
normalDataIris <- as.data.frame(lapply(dataIris[,1:6], normal))
head(normalDataIris)
# Put outcome variable back on and rename
normalDataIris <- cbind(normalDataIris, dataIris[,7])
names(normalDataIris)[7] <- "CarClass"
# Check Data
colnames(normalDataIris)
head(normalDataIris)
# Split into training set (80%) and testing set (20%)
set.seed(800) #seed can be any number
normalDataIris.split <- sample(2, nrow(normalDataIris),replace = TRUE, prob = c(0.8, 0.2))
# Create training and testing dataset without outcome labels.
# Use just the first 23 variavles
normalDataIris.train.labels <- normalDataIris[normalDataIris.split == 1, 5]
normalDataIris.test.labels <- normalDataIris[normalDataIris.split == 2, 5]
# Create outcome labels
normalDataIris.train <- normalDataIris[normalDataIris.split == 1, 1:4]
normalDataIris.test <- normalDataIris[normalDataIris.split == 2, 1:4]
# Build classifier for test data
# k = number of neighbors to compare; odd n avoids ties.
# Try for several k and check accuracy
normalDataIris.pred <- knn(train = normalDataIris.train,
test = normalDataIris.test,
cl = normalDataIris.train.labels,       # true class
k = 3)                         # n neighbors
# Compare predicted outcome to observed outcome
table(normalDataIris.pred, normalDataIris.test.labels)
View(dataIris)
View(normalDataIris.test)
View(normalDataIris.train)
# Clean up #####################
rm(list = ls())
install.packages("pacman")
install.packages("pacman")
library(pacman)
# Install class for knn classification
pacman::p_load("class")
# Load Data ############################
# Read csv
dataIris <- read.csv("car_data.csv", header = TRUE)
View(dataIris)
colnames(dataIris)
head(dataIris)       # Show the first 6 cases
normal <- function(x) {
norm <- ((x - min(x))/(max(x)- min(x)))
return (norm)
}
View(normal)
# Apply function to data frame without ID and default
normalDataIris <- as.data.frame(lapply(dataIris[,1:6], normal))
View(normalDataIris)
head(normalDataIris)
# Put outcome variable back on and rename
normalDataIris <- cbind(normalDataIris, dataIris[,7])
names(normalDataIris)[7] <- "CarClass"
# Check Data
colnames(normalDataIris)
head(normalDataIris)
# Split into training set (80%) and testing set (20%)
set.seed(800) #seed can be any number
normalDataIris.split <- sample(2, nrow(normalDataIris),replace = TRUE, prob = c(0.8, 0.2))
View(normalDataIris)
View(dataIris)
# Create training and testing dataset without outcome labels.
# Use just the first 23 variavles
normalDataIris.train.labels <- normalDataIris[normalDataIris.split == 1, 5]
normalDataIris.test.labels <- normalDataIris[normalDataIris.split == 2, 5]
View(normal)
# Create outcome labels
normalDataIris.train <- normalDataIris[normalDataIris.split == 1, 1:4]
View(normalDataIris.train)
# Create outcome labels
normalDataIris.train <- normalDataIris[normalDataIris.split == 1, 1:6]
View(normalDataIris.train)
normalDataIris.test <- normalDataIris[normalDataIris.split == 2, 1:6]
View(normalDataIris.train)
# Build classifier for test data
# k = number of neighbors to compare; odd n avoids ties.
# Try for several k and check accuracy
normalDataIris.pred <- knn(train = normalDataIris.train,
test = normalDataIris.test,
cl = normalDataIris.train.labels,       # true class
k = 5)                         # n neighbors
# Compare predicted outcome to observed outcome
table(normalDataIris.pred, normalDataIris.test.labels)
# Create training and testing dataset without outcome labels.
# Use just the first 23 variavles
normalDataIris.train.labels <- normalDataIris[normalDataIris.split == 1, 6]
normalDataIris.test.labels <- normalDataIris[normalDataIris.split == 2, 6]
# Create outcome labels
normalDataIris.train <- normalDataIris[normalDataIris.split == 1, 1:6]
normalDataIris.test <- normalDataIris[normalDataIris.split == 2, 1:6]
# Build classifier for test data
# k = number of neighbors to compare; odd n avoids ties.
# Try for several k and check accuracy
normalDataIris.pred <- knn(train = normalDataIris.train,
test = normalDataIris.test,
cl = normalDataIris.train.labels,       # true class
k = 5)                         # n neighbors
# Compare predicted outcome to observed outcome
table(normalDataIris.pred, normalDataIris.test.labels)
# Create outcome labels
normalDataIris.train <- normalDataIris[normalDataIris.split == 1, 1:5]
normalDataIris.test <- normalDataIris[normalDataIris.split == 2, 1:5]
# Build classifier for test data
# k = number of neighbors to compare; odd n avoids ties.
# Try for several k and check accuracy
normalDataIris.pred <- knn(train = normalDataIris.train,
test = normalDataIris.test,
cl = normalDataIris.train.labels,       # true class
k = 5)                         # n neighbors
# Compare predicted outcome to observed outcome
table(normalDataIris.pred, normalDataIris.test.labels)
# Load Data ############################
# Read csv
dataCar <- read.csv("car_data.csv", header = TRUE)
colnames(dataCar)
head(dataCar)       # Show the first 6 cases
normal <- function(x) {
norm <- ((x - min(x))/(max(x)- min(x)))
return (norm)
}
# Apply function to data frame without ID and default
normalDataCar <- as.data.frame(lapply(dataCar[,1:6], normal))
head(normalDataCar)
# Put outcome variable back on and rename
normalDataCar <- cbind(normalDataCar, dataCar[,7])
names(normalDataCar)[7] <- "CarClass"
# Check Data
colnames(normalDataCar)
head(normalDataCar)
# Split into training set (80%) and testing set (20%)
set.seed(800) #seed can be any number
normalDataCar.split <- sample(2, nrow(normalDataCar),replace = TRUE, prob = c(0.8, 0.2))
# Create training and testing dataset without outcome labels.
# Use just the first 23 variavles
normalDataCar.train.labels <- normalDataCar[normalDataCar.split == 1, 7]
normalDataCar.test.labels <- normalDataCar[normalDataCar.split == 2, 7]
# Create outcome labels
normalDataCar.train <- normalDataCar[normalDataCar.split == 1, 1:6]
normalDataCar.test <- normalDataCar[normalDataCar.split == 2, 1:6]
# Build classifier for test data
# k = number of neighbors to compare; odd n avoids ties.
# Try for several k and check accuracy
normalDataCar.pred <- knn(train = normalDataCar.train,
test = normalDataCar.test,
cl = normalDataCar.train.labels,       # true class
k = 3)                         # n neighbors
# Compare predicted outcome to observed outcome
table(normalDataCar.pred, normalDataCar.test.labels)
View(normalDataIris.train)
View(normalDataCar)
View(normalDataCar.test)
# Clean up #####################
rm(list = ls())
# Install class for knn classification
pacman::p_load("class")
# Load Data ############################
# Read csv
car_data <- read.csv("car_data.csv", header = TRUE)
View(car_data)
colnames(car_data)
head(car_data)       # Show the first 6 cases
normal <- function(x) {
norm <- ((x - min(x))/(max(x)- min(x)))
return (norm)
}
# Apply function to data frame without ID and default
normal_car_data <- as.data.frame(lapply(car_data[,1:6], normal))
head(normal_car_data)
View(normal_car_data)
# Put outcome variable back on and rename
normal_car_data <- cbind(normal_car_data, car_data[,7])
names(normal_car_data)[7] <- "CarClass"
# Check Data
colnames(normal_car_data)
head(normal_car_data)
# Split into training set (80%) and testing set (20%)
set.seed(800) #seed can be any number
# Split into training set (80%) and testing set (20%)
set.seed(900) #seed can be any number
# Split into training set (80%) and testing set (20%)
set.seed(800) #seed can be any number
normal_car_data.split <- sample(2, nrow(normal_car_data),replace = TRUE, prob = c(0.95, 0.05))
# Create training and testing dataset without outcome labels.
# Use just the first 23 variavles
normal_car_data.train.labels <- normal_car_data[normal_car_data.split == 1, 7]
normal_car_data.test.labels <- normal_car_data[normal_car_data.split == 2, 7]
# Create outcome labels
normal_car_data.train <- normal_car_data[normal_car_data.split == 1, 1:6]
normal_car_data.test <- normal_car_data[normal_car_data.split == 2, 1:6]
View(normal_car_data)
View(normal_car_data.test)
View(normal_car_data.train)
# Build classifier for test data
# k = number of neighbors to compare; odd n avoids ties.
# Try for several k and check accuracy
normal_car_data.pred <- knn(train = normal_car_data.train,
test = normal_car_data.test,
cl = normal_car_data.train.labels,       # true class
k = 3)                         # n neighbors
# Compare predicted outcome to observed outcome
table(normal_car_data.pred, normal_car_data.test.labels)
normal_car_data.split <- sample(2, nrow(normal_car_data),replace = TRUE, prob = c(0.9, 0.1))
# Create training and testing dataset without outcome labels.
# Use just the first 23 variavles
normal_car_data.train.labels <- normal_car_data[normal_car_data.split == 1, 7]
normal_car_data.test.labels <- normal_car_data[normal_car_data.split == 2, 7]
# Create outcome labels
normal_car_data.train <- normal_car_data[normal_car_data.split == 1, 1:6]
normal_car_data.test <- normal_car_data[normal_car_data.split == 2, 1:6]
# Build classifier for test data
# k = number of neighbors to compare; odd n avoids ties.
# Try for several k and check accuracy
normal_car_data.pred <- knn(train = normal_car_data.train,
test = normal_car_data.test,
cl = normal_car_data.train.labels,       # true class
k = 3)                         # n neighbors
# Compare predicted outcome to observed outcome
table(normal_car_data.pred, normal_car_data.test.labels)
# Install class for knn classification
pacman::p_load("class")
# Load Data ############################
# Read csv
car_data <- read.csv("car_data.csv", header = TRUE)
colnames(car_data)
head(car_data)       # Show the first 6 cases
normal <- function(x) {
norm <- ((x - min(x))/(max(x)- min(x)))
return (norm)
}
# Apply function to data frame without ID and default
normal_car_data <- as.data.frame(lapply(car_data[,1:6], normal))
head(normal_car_data)
# Put outcome variable back on and rename
normal_car_data <- cbind(normal_car_data, car_data[,7])
names(normal_car_data)[7] <- "CarClass"
# Check Data
colnames(normal_car_data)
head(normal_car_data)
# Split into training set (80%) and testing set (20%)
set.seed(800) #seed can be any number
normal_car_data.split <- sample(2, nrow(normal_car_data),replace = TRUE, prob = c(0.9, 0.1))
# Create training and testing dataset without outcome labels.
# Use just the first 23 variavles
normal_car_data.train.labels <- normal_car_data[normal_car_data.split == 1, 7]
normal_car_data.test.labels <- normal_car_data[normal_car_data.split == 2, 7]
# Create outcome labels
normal_car_data.train <- normal_car_data[normal_car_data.split == 1, 1:6]
normal_car_data.test <- normal_car_data[normal_car_data.split == 2, 1:6]
# Build classifier for test data
# k = number of neighbors to compare; odd n avoids ties.
# Try for several k and check accuracy
normal_car_data.pred <- knn(train = normal_car_data.train,
test = normal_car_data.test,
cl = normal_car_data.train.labels,       # true class
k = 3)                         # n neighbors
# Compare predicted outcome to observed outcome
table(normal_car_data.pred, normal_car_data.test.labels)
View(normal_car_data.test)
View(normal_car_data.train)
# Install class for knn classification
pacman::p_load("class")
# Load Data ############################
# Read csv
car_data <- read.csv("car_data.csv", header = TRUE)
colnames(car_data)
head(car_data)       # Show the first 6 cases
normal <- function(x) {
norm <- ((x - min(x))/(max(x)- min(x)))
return (norm)
}
# Apply function to data frame without ID and default
normal_car_data <- as.data.frame(lapply(car_data[,1:6], normal))
head(normal_car_data)
# Put outcome variable back on and rename
normal_car_data <- cbind(normal_car_data, car_data[,7])
names(normal_car_data)[7] <- "CarClass"
# Check Data
colnames(normal_car_data)
head(normal_car_data)
# Split into training set (80%) and testing set (20%)
set.seed(800) #seed can be any number
normal_car_data.split <- sample(2, nrow(normal_car_data),replace = TRUE, prob = c(0.9, 0.1))
# Create training and testing dataset without outcome labels.
# Use just the first 23 variavles
normal_car_data.train.labels <- normal_car_data[normal_car_data.split == 1, 7]
normal_car_data.test.labels <- normal_car_data[normal_car_data.split == 2, 7]
# Create outcome labels
normal_car_data.train <- normal_car_data[normal_car_data.split == 1, 1:6]
normal_car_data.test <- normal_car_data[normal_car_data.split == 2, 1:6]
# Build classifier for test data
# k = number of neighbors to compare; odd n avoids ties.
# Try for several k and check accuracy
normal_car_data.pred <- knn(train = normal_car_data.train,
test = normal_car_data.test,
cl = normal_car_data.train.labels,       # true class
k = 5)                         # n neighbors
# Compare predicted outcome to observed outcome
table(normal_car_data.pred, normal_car_data.test.labels)
